{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Data Access Times for AWS and Glade Zarr Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "import s3fs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Dask to Speed up Computations\n",
    "\n",
    "* We are testing data transfer rate, so we use many workers to make sure data bandwidth is as saturated as possible.\n",
    "\n",
    "* It's a simple plotting task, so we don't ask for much walltime or memory per worker, to get workers more quickly from the scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from ncar_jobqueue import NCARCluster\n",
    "\n",
    "num_jobs = 30\n",
    "walltime = \"1:00:00\"\n",
    "memory='2GB' \n",
    "#cluster = NCARCluster(cores=num_jobs, processes=1, memory=memory, walltime=walltime)\n",
    "#cluster.scale(jobs=num_jobs)\n",
    "cluster = NCARCluster()\n",
    "\n",
    "from distributed import Client\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☝️ Link to scheduler dashboard will appear above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-define some data constraints\n",
    "data_var = 'prec'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Access Using an Intake Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "\n",
    "# Open collection description file\n",
    "catalog_url = \"https://raw.githubusercontent.com/NCAR/notebook-gallery/add-aws-catalog/catalogs/aws-na-cordex.json\"\n",
    "col = intake.open_esm_datastore(catalog_url)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first few lines of the catalog\n",
    "col.df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show expanded version of collection structure with details\n",
    "import pprint\n",
    "\n",
    "uniques = col.unique(\n",
    "    columns=[\"variable\", \"scenario\", \"grid\", \"gcm\", \"rcm\"]\n",
    ")\n",
    "pprint.pprint(uniques, compact=True, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data into xarray from a catalog using intake-esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_subset = col.search(\n",
    "    variable=data_var,\n",
    "    grid=\"NAM-44i\",\n",
    "    scenario=[\"hist\"],\n",
    ")\n",
    "\n",
    "col_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_subset.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load catalog entries for subset into a dictionary of xarray datasets\n",
    "dsets = col_subset.to_dataset_dict(\n",
    "    zarr_kwargs={\"consolidated\": True}, storage_options={\"anon\": True}\n",
    ")\n",
    "print(f\"\\nDataset dictionary keys:\\n {dsets.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Xarray datasets corresponding to the three experiments\n",
    "ds = dsets[\"day.hist.NAM-44i.raw\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternate methods to access data when the store path is known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aws_store(store_name):\n",
    "    \"\"\"Given a store name, open that store on Amazon AWS and return an XArray dataset object.\"\"\"\n",
    "\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "    root = \"s3://ncar-na-cordex\"\n",
    "    data_frequency = \"day\"\n",
    "    full_path = f\"{root}/{data_frequency}/{store_name}\"\n",
    "    store = s3fs.S3Map(root=full_path, s3=fs)\n",
    "\n",
    "    ds = xr.open_zarr(store, consolidated=True)\n",
    "    return ds   \n",
    "\n",
    "# Reference a particular Store by name.\n",
    "store_name = 'prec.rcp85.day.NAM-44i.raw.zarr'\n",
    "\n",
    "# Open up the Store for data read.\n",
    "ds = get_aws_store(store_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glade_store(store_name):\n",
    "    \"\"\"Given a store name, open that store on NCAR Glade and return an XArray dataset object.\"\"\"\n",
    "\n",
    "    root = \"/glade/scratch/bonnland/na-cordex/zarr-publish\"\n",
    "    full_path = f\"{root}/{store_name}\"\n",
    "\n",
    "    ds = xr.open_zarr(full_path, consolidated=True)\n",
    "    return ds    \n",
    "\n",
    "# Reference a particular Store by name.\n",
    "store_name = 'prec.rcp85.day.NAM-44i.raw.zarr'\n",
    "\n",
    "# Open up the Store for data read.\n",
    "ds = get_glade_store(store_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Function to Create a Single Map Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMap(ax, map_slice, date_object=None, member_id=None):\n",
    "    '''Create a map plot on the given axes, with min/max as text'''\n",
    "\n",
    "    ax.imshow(map_slice, origin='lower')\n",
    "\n",
    "    #minval = map_slice.min(dim = ['lat', 'lon'])\n",
    "    #maxval = map_slice.max(dim = ['lat', 'lon'])\n",
    "\n",
    "    # Format values to have at least 4 digits of precision.\n",
    "    #ax.text(0.01, 0.03, \"%4g\" % minval, transform=ax.transAxes, fontsize=12)\n",
    "    #ax.text(0.99, 0.03, \"%4g\" % maxval, transform=ax.transAxes, fontsize=12, horizontalalignment='right')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    if date_object:\n",
    "        ax.set_title(date_object.values.astype(str)[:10], fontsize=12)\n",
    "        \n",
    "    if member_id:\n",
    "        ax.set_ylabel(member_id, fontsize=12)\n",
    "        \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Producing Maps of First, Middle, Last Timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValidDateIndexes(member_slice):\n",
    "    '''Search for the first and last dates with finite values.'''\n",
    "    min_values = member_slice.min(dim = ['lat', 'lon'])\n",
    "    is_finite = np.isfinite(min_values)\n",
    "    finite_indexes = np.where(is_finite)\n",
    "    start_index = finite_indexes[0][0]\n",
    "    end_index = finite_indexes[0][-1]\n",
    "    #print(f'start ={start_index}, end={end_index}')\n",
    "    return start_index, end_index\n",
    "\n",
    "\n",
    "def plot_first_mid_last(ds, data_var):\n",
    "    # Generate plot. \n",
    "    #\n",
    "    # With 30 workers, expect 1 minute walltime for computation and 1-2 minutes for plot rendering on Glade.\n",
    "    #\n",
    "    member_names = ds.coords['member_id'].values[0:2]\n",
    "    \n",
    "    numEnsembleMembers = member_names.size\n",
    "\n",
    "    numPlotsPerPage = numEnsembleMembers\n",
    "    numPlotCols = 3\n",
    "\n",
    "    figWidth = 18 \n",
    "    figHeight = 12 #20\n",
    "\n",
    "    fig, axs = plt.subplots(numPlotsPerPage, numPlotCols, figsize=(figWidth, figHeight), constrained_layout=True)\n",
    "\n",
    "    for index in np.arange(numEnsembleMembers):\n",
    "        mem_id = member_names[index]\n",
    "        data_slice = ds[data_var].sel(member_id=mem_id)\n",
    "           \n",
    "        start_index, end_index = getValidDateIndexes(data_slice)\n",
    "        midDateIndex = np.floor(len(ds.time) / 2).astype(int)\n",
    "\n",
    "        startDate = ds.time[start_index]\n",
    "        first_step = data_slice.sel(time=startDate) \n",
    "        ax = axs[index, 0]\n",
    "        plotMap(ax, first_step, startDate, mem_id)\n",
    "\n",
    "        midDate = ds.time[midDateIndex]\n",
    "        mid_step = data_slice.sel(time=midDate)   \n",
    "        ax = axs[index, 1]\n",
    "        plotMap(ax, mid_step, midDate)\n",
    "\n",
    "        endDate = ds.time[end_index]\n",
    "        last_step = data_slice.sel(time=endDate)            \n",
    "        ax = axs[index, 2]\n",
    "        plotMap(ax, last_step, endDate)\n",
    "             \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Time Series Plots over Multiple Pages\n",
    "These also mark the locations of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries(ds, data_var):\n",
    "    # Generate plot. \n",
    "    #\n",
    "    # With 30 workers, expect 1 minute walltime for computation and 1-2 minutes for plot rendering on Glade.\n",
    "    #\n",
    "    member_names = ds.coords['member_id'].values[0:4]\n",
    "    numEnsembleMembers = member_names.size\n",
    "\n",
    "    numPages = 1\n",
    "    numPlotsPerPage = 4\n",
    "    numPlotCols = 1\n",
    "\n",
    "    figWidth = 25 \n",
    "    figHeight = 20\n",
    "    linewidth = 0.5\n",
    "    \n",
    "    for pageNum in range(numPages):\n",
    "\n",
    "        # Plot the aggregate statistics across time.\n",
    "        fig, axs = plt.subplots(numPlotsPerPage, numPlotCols, figsize=(figWidth, figHeight))\n",
    "        \n",
    "        for index in np.arange(numEnsembleMembers):\n",
    "            mem_id = member_names[index]\n",
    "            data_slice = ds[data_var].sel(member_id=mem_id)\n",
    "            unit_string = ds[data_var].attrs['units']\n",
    "            \n",
    "            min_vals = data_slice.min(dim = ['lat', 'lon'])\n",
    "            max_vals = data_slice.max(dim = ['lat', 'lon'])\n",
    "            mean_vals = data_slice.mean(dim = ['lat', 'lon'])\n",
    "            std_vals = data_slice.std(dim = ['lat', 'lon'])\n",
    "\n",
    "            nan_indexes = np.isnan(min_vals)\n",
    "            nan_times = ds.time[nan_indexes]\n",
    "\n",
    "            axs[index].plot(ds.time, min_vals, linewidth=linewidth, label='min')\n",
    "            axs[index].plot(ds.time, max_vals, linewidth=linewidth, label='max')\n",
    "            axs[index].plot(ds.time, mean_vals, linewidth=linewidth, label='mean')\n",
    "            axs[index].plot(ds.time, std_vals, linewidth=linewidth, label='std')\n",
    "            \n",
    "            ymin, ymax = axs[index].get_ylim()\n",
    "            rug_y = ymin + 0.01*(ymax-ymin)\n",
    "            axs[index].plot(nan_times, [rug_y]*len(nan_times), '|', color='m', label='isnan')\n",
    "            axs[index].set_title(mem_id, fontsize=20)\n",
    "            axs[index].legend(loc='upper right')\n",
    "            axs[index].set_ylabel(unit_string)\n",
    "\n",
    "        plt.tight_layout(pad=10.2, w_pad=3.5, h_pad=3.5)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Zarr Data from Different Sources and Record Plotting Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot First, Middle, and Final Timesteps  (Less Data Intensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Plot using a Zarr Store obtained from an earlier step in the notebook.\n",
    "plot_first_mid_last(ds, data_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Time Series (More Data Intensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Plot using a Zarr Store obtained from an earlier step in the notebook.\n",
    "plot_timeseries(ds, data_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Release the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
